{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [comment_text, toxic, severe_toxic, obscene, threat, insult, identity_hate]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df = df.drop('id',axis=1)\n",
    "df.head(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and special characters\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    # Additional preprocessing steps can be added here\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed comment_text:\n",
      "0    explanation\\nwhy the edits made under my usern...\n",
      "1    daww he matches this background colour im seem...\n",
      "2    hey man im really not trying to edit war its j...\n",
      "3    \\nmore\\ni cant make any real suggestions on im...\n",
      "4    you sir are my hero any chance you remember wh...\n",
      "Name: comment_text, dtype: object\n",
      "\n",
      "Slang labels:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: slang, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "df['comment_text'] = df['comment_text'].apply(preprocess_text)\n",
    "\n",
    "# Create the 'slang' column based on the presence of toxic labels\n",
    "df['slang'] = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].any(axis=1).astype(int)\n",
    "\n",
    "# Separate the features (X) and target (y)\n",
    "X = df['comment_text']\n",
    "y = df['slang']\n",
    "# df.head(0)\n",
    "print(\"Preprocessed comment_text:\")\n",
    "print(X.head())\n",
    "print(\"\\nSlang labels:\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24915     you are a fat geeky prick who has nothing to d...\n",
       "75819     agent x2 basically thanks  with a little more ...\n",
       "53891     why are my posts being deleted \\n\\ni have trie...\n",
       "154159    \\n\\n controlled demolitions and common sense  ...\n",
       "13040       i do not understand your reply  blaxthos  t  c \n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "x_train, x_test,y_train, y_test = train_test_split(X,y, test_size=0.4,random_state=1)\n",
    "# x_train.head(0)\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'svm__C': 1, 'svm__kernel': 'linear'}\n",
      "Best cross-validation score: 0.9463125073926043\n",
      "Test set score: 94.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Sample data\n",
    "sample_size = 20000  # Adjust sample size as needed\n",
    "x_sample = X[:sample_size]\n",
    "y_sample = y[:sample_size]\n",
    "\n",
    "# Split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_sample, y_sample, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "x_train_tfidf = tfidf_vectorizer.fit_transform(x_train)\n",
    "x_test_tfidf = tfidf_vectorizer.transform(x_test)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# SVM Classifier with Grid Search\n",
    "svm_pipeline = Pipeline([\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "# Define parameters for grid search\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__kernel': ['linear', 'rbf'],\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(svm_pipeline, param_grid, cv=3, n_jobs=-1)\n",
    "grid_search.fit(x_train_tfidf, y_train_encoded)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_score = grid_search.score(x_test_tfidf, y_test_encoded)\n",
    "print(\"Test set score:\", test_score*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      3583\n",
      "           1       0.94      0.53      0.68       417\n",
      "\n",
      "    accuracy                           0.95      4000\n",
      "   macro avg       0.95      0.76      0.83      4000\n",
      "weighted avg       0.95      0.95      0.94      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = grid_search.predict(x_test_tfidf)\n",
    "class_names = label_encoder.inverse_transform(range(len(label_encoder.classes_)))\n",
    "\n",
    "report = classification_report(y_test_encoded, y_pred, target_names=None)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input string: i hate nigger\n",
      "Predicted toxicity: Toxic\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the input string (assuming preprocess_text function is defined)\n",
    "def preprocess_input(text):\n",
    "    # Apply the same preprocessing steps used during training\n",
    "    text = preprocess_text(text)\n",
    "    return text\n",
    "\n",
    "# Vectorize the preprocessed input string\n",
    "def vectorize_input(input_string, tfidf_vectorizer):\n",
    "    # Preprocess the input string\n",
    "    preprocessed_input = preprocess_input(input_string)\n",
    "    # Vectorize the preprocessed input using the TF-IDF vectorizer\n",
    "    input_vector = tfidf_vectorizer.transform([preprocessed_input])\n",
    "    return input_vector\n",
    "\n",
    "# Example input string to check toxicity\n",
    "input_string = input(\"Enter a comment: \")\n",
    "\n",
    "# Vectorize the input string\n",
    "input_vector = vectorize_input(input_string, tfidf_vectorizer)\n",
    "\n",
    "# Use the trained SVM model to predict toxicity\n",
    "predicted_label = grid_search.predict(input_vector)[0]\n",
    "\n",
    "# Determine if the comment is toxic or not based on the predicted label\n",
    "is_toxic = predicted_label == 1\n",
    "\n",
    "# Print the prediction\n",
    "print(\"Input string:\", input_string)\n",
    "print(\"Predicted toxicity:\", \"Toxic\" if is_toxic else \"Not Toxic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_classifier = SVC()\n",
    "\n",
    "# # Train the SVM classifier\n",
    "# svm_classifier.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_pred = svm_classifier.predict(x_test_tfidf)\n",
    "\n",
    "# # Calculate the accuracy\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
